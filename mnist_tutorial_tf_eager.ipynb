{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import functools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTModel(tfe.Network):\n",
    "  \"\"\"MNIST Network.\n",
    "  Network structure is equivalent to:\n",
    "  https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "  and\n",
    "  https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py\n",
    "  But written using the tf.layers API.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, data_format):\n",
    "    \"\"\"Creates a model for classifying a hand-written digit.\n",
    "    Args:\n",
    "      data_format: Either 'channels_first' or 'channels_last'.\n",
    "        'channels_first' is typically faster on GPUs while 'channels_last' is\n",
    "        typically faster on CPUs. See\n",
    "        https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "    \"\"\"\n",
    "    super(MNISTModel, self).__init__(name='')\n",
    "    if data_format == 'channels_first':\n",
    "        self._input_shape = [-1, 1, 28, 28]\n",
    "    else:\n",
    "        assert data_format == 'channels_last'\n",
    "        self._input_shape = [-1, 28, 28, 1]\n",
    "    self.conv1 = self.track_layer(\n",
    "        tf.layers.Conv2D(32, 5, data_format=data_format, activation=tf.nn.relu))\n",
    "    self.conv2 = self.track_layer(\n",
    "        tf.layers.Conv2D(64, 5, data_format=data_format, activation=tf.nn.relu))\n",
    "    self.fc1 = self.track_layer(tf.layers.Dense(1024, activation=tf.nn.relu))\n",
    "    self.fc2 = self.track_layer(tf.layers.Dense(10))\n",
    "    self.dropout = self.track_layer(tf.layers.Dropout(0.5))\n",
    "    self.max_pool2d = self.track_layer(\n",
    "        tf.layers.MaxPooling2D(\n",
    "            (2, 2), (2, 2), padding='SAME', data_format=data_format))\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    \"\"\"Computes labels from inputs.\n",
    "    Users should invoke __call__ to run the network, which delegates to this\n",
    "    method (and not call this method directly).\n",
    "    Args:\n",
    "      inputs: A batch of images as a Tensor with shape [batch_size, 784].\n",
    "      training: True if invoked in the context of training (causing dropout to\n",
    "        be applied).  False otherwise.\n",
    "    Returns:\n",
    "      A Tensor with shape [batch_size, 10] containing the predicted logits\n",
    "      for each image in the batch, for each of the 10 classes.\n",
    "    \"\"\"\n",
    "\n",
    "    x = tf.reshape(inputs, self._input_shape)\n",
    "    x = self.conv1(x)\n",
    "    x = self.max_pool2d(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.max_pool2d(x)\n",
    "    x = tf.layers.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    if training:\n",
    "      x = self.dropout(x)\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "  \"\"\"Returns training and test tf.data.Dataset objects.\"\"\"\n",
    "  data = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "  train_ds = tf.data.Dataset.from_tensor_slices((data.train.images,\n",
    "                                                 data.train.labels))\n",
    "  test_ds = tf.data.Dataset.from_tensor_slices((data.test.images, data.test.labels))\n",
    "  return (train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(predictions, labels):\n",
    "  return tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "      logits=predictions, labels=labels))\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "  return tf.reduce_sum(\n",
    "      tf.cast(\n",
    "          tf.equal(\n",
    "              tf.argmax(predictions, axis=1,\n",
    "                        output_type=tf.int64),\n",
    "              tf.argmax(labels, axis=1,\n",
    "                        output_type=tf.int64)),\n",
    "          dtype=tf.float32)) / float(predictions.shape[0].value)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, dataset, log_interval=None):\n",
    "  \"\"\"Trains model on `dataset` using `optimizer`.\"\"\"\n",
    "\n",
    "  tf.train.get_or_create_global_step()\n",
    "\n",
    "  def model_loss(labels, images):\n",
    "    prediction = model(images, training=True)\n",
    "    loss_value = loss(prediction, labels)\n",
    "    tf.contrib.summary.scalar('loss', loss_value)\n",
    "    tf.contrib.summary.scalar('accuracy',\n",
    "                              compute_accuracy(prediction, labels))\n",
    "    return loss_value\n",
    "\n",
    "  for (batch, (images, labels)) in enumerate(tfe.Iterator(dataset)):\n",
    "    with tf.contrib.summary.record_summaries_every_n_global_steps(10):\n",
    "      batch_model_loss = functools.partial(model_loss, labels, images)\n",
    "      optimizer.minimize(\n",
    "          batch_model_loss, global_step=tf.train.get_global_step())\n",
    "      #if log_interval and batch % log_interval == 0:\n",
    "      #  print('Batch #%d\\tLoss: %.6f' % (batch, batch_model_loss()))\n",
    "\n",
    "\n",
    "def test(model, dataset):\n",
    "  \"\"\"Perform an evaluation of `model` on the examples from `dataset`.\"\"\"\n",
    "  avg_loss = tfe.metrics.Mean('loss')\n",
    "  accuracy = tfe.metrics.Accuracy('accuracy')\n",
    "\n",
    "  for (images, labels) in tfe.Iterator(dataset):\n",
    "    predictions = model(images, training=False)\n",
    "    avg_loss(loss(predictions, labels))\n",
    "    accuracy(tf.argmax(predictions, axis=1, output_type=tf.int64),\n",
    "             tf.argmax(labels, axis=1, output_type=tf.int64))\n",
    "  print('Test set: Average loss: %.4f, Accuracy: %4f%%' %\n",
    "        (avg_loss.result(), 100 * accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def craft_adv(model, dataset):\n",
    "  \"\"\"Craft adversarial examples of `model` based on the examples from `dataset`.\"\"\"\n",
    "  avg_loss = tfe.metrics.Mean('loss_adv')\n",
    "  accuracy = tfe.metrics.Accuracy('accuracy_adv')\n",
    "\n",
    "  def loss_wrapper(inputs, labels, model):\n",
    "    preds = model(inputs, training=False)\n",
    "    return loss(preds, labels)\n",
    "\n",
    "  def extract_input_grad(grad_and_vars):\n",
    "    for i in range(len(grad_and_vars)):\n",
    "      if grad_and_vars[i][1].name == 'inputs:0':\n",
    "        return grad_and_vars[i][0]\n",
    "\n",
    "  gradients_fn = tfe.implicit_gradients(loss_wrapper)\n",
    "  images_variable = tfe.Variable(tf.zeros((100, 784)), name='inputs')\n",
    "  for (images, labels) in tfe.Iterator(dataset):\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    tf.assign(images_variable, images)\n",
    "    grad_and_vars = gradients_fn(images_variable, labels, model)\n",
    "    input_grad = extract_input_grad(grad_and_vars)\n",
    "    normalized_grad = tf.sign(input_grad)\n",
    "    scaled_grad = 0.3 * normalized_grad\n",
    "\n",
    "    perturbed_images = images + scaled_grad\n",
    "    perturbed_images = tf.clip_by_value(perturbed_images, 0, 1)\n",
    "    #plt.imshow(tf.reshape(images[-1], (28, 28)), cmap='gray')\n",
    "    #plt.imshow(tf.reshape(perturbed_images[-1], (28, 28)), cmap='gray')\n",
    "    #exit()\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    predictions = model(perturbed_images, training=False)\n",
    "    avg_loss(loss(predictions, labels))\n",
    "    accuracy(tf.argmax(predictions, axis=1, output_type=tf.int64),\n",
    "             tf.argmax(labels, axis=1, output_type=tf.int64))\n",
    "  print('\\nAdversarial test set: Average loss: %.4f, Accuracy: %4f%%\\n' %\n",
    "        (avg_loss.result(), 100 * accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device /gpu:0, and data format channels_first.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Train time for epoch #1 (global step 860): 8.537302\n",
      "Test set: Average loss: 0.1628, Accuracy: 95.260000%\n",
      "\n",
      "Train time for epoch #2 (global step 1720): 8.659573\n",
      "Test set: Average loss: 0.0937, Accuracy: 97.110000%\n",
      "\n",
      "Train time for epoch #3 (global step 2580): 7.923543\n",
      "Test set: Average loss: 0.0729, Accuracy: 97.800000%\n",
      "\n",
      "Train time for epoch #4 (global step 3440): 8.285579\n",
      "Test set: Average loss: 0.0582, Accuracy: 98.210000%\n",
      "\n",
      "Adversarial test set: Average loss: 6.1681, Accuracy: 2.670000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  tfe.enable_eager_execution()\n",
    "\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--data-dir', type=str, default='/tmp/tensorflow/mnist/input_data',\n",
    "          help='Directory for storing input data')\n",
    "  parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "          help='input batch size for training (default: 64)')\n",
    "  parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "          help='how many batches to wait before logging training status')\n",
    "  parser.add_argument('--output_dir', type=str, default=None, metavar='N',\n",
    "          help='Directory to write TensorBoard summaries')\n",
    "  parser.add_argument('--checkpoint_dir', type=str, default='/tmp/tensorflow/mnist/checkpoints/', metavar='N',\n",
    "          help='Directory to save checkpoints in (once per epoch)')\n",
    "  parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "          help='learning rate (default: 0.01)')\n",
    "  parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "          help='SGD momentum (default: 0.5)')\n",
    "  parser.add_argument('--no-gpu', action='store_true', default=False,\n",
    "          help='disables GPU usage even if a GPU is available')\n",
    "  args, unparsed = parser.parse_known_args()\n",
    "\n",
    "  (device, data_format) = ('/gpu:0', 'channels_first')\n",
    "  if args.no_gpu or tfe.num_gpus() <= 0:\n",
    "    (device, data_format) = ('/cpu:0', 'channels_last')\n",
    "  print('Using device %s, and data format %s.' % (device, data_format))\n",
    "\n",
    "  # Load the datasets\n",
    "  (train_ds, test_ds) = load_data(args.data_dir)\n",
    "  train_ds = train_ds.shuffle(60000).batch(args.batch_size)\n",
    "  test_ds = test_ds.batch(100)\n",
    "\n",
    "  # Create the model and optimizer\n",
    "  model = MNISTModel(data_format)\n",
    "  optimizer = tf.train.MomentumOptimizer(args.lr, args.momentum)\n",
    "\n",
    "  if args.output_dir:\n",
    "    train_dir = os.path.join(args.output_dir, 'train')\n",
    "    test_dir = os.path.join(args.output_dir, 'eval')\n",
    "    tf.gfile.MakeDirs(args.output_dir)\n",
    "  else:\n",
    "    train_dir = None\n",
    "    test_dir = None\n",
    "\n",
    "\n",
    "  with tf.device(device):\n",
    "    for epoch in range(1, 5):\n",
    "      global_step = tf.train.get_or_create_global_step()\n",
    "      start = time.time()\n",
    "      train_one_epoch(model, optimizer, train_ds, args.log_interval)\n",
    "      end = time.time()\n",
    "      print('\\nTrain time for epoch #%d (global step %d): %f' % (\n",
    "            epoch, global_step.numpy(), end - start))\n",
    "      test(model, test_ds)\n",
    "    craft_adv(model, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
